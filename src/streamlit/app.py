import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import streamlit as st
import pandas as pd
from src.core.mcap_processor import McapProcessor
from src.models.model_functions import ModelFunctions
import os

def run_streamlit_app():
    # Configuration de la page en mode large
    st.set_page_config(
        page_title="Affectation des Profils",
        page_icon="üìä",
        layout="wide",  # Utilise toute la largeur disponible
        initial_sidebar_state="expanded"
    )
    
    st.cache_data.clear()
    st.title("Affectation des Profils")
    
    # Configuration de la page
    st.sidebar.header("Configuration")
    
    # Upload des fichiers
    mca_file = st.sidebar.file_uploader("Charger le fichier MCA", type=['csv'])
    mcp_file = st.sidebar.file_uploader("Charger le fichier MCP", type=['csv'])
    
    # S√©lection du mod√®le
    model_options = {
        'Mod√®le 1': 'model1',
        'Mod√®le 2': 'model2',
        'Mod√®le 3': 'model3',
        'Mod√®le 4': 'model4',
        'Mod√®le 5': 'model5'
    }
    selected_model = st.sidebar.selectbox(
        "Choisir le mod√®le",
        options=list(model_options.keys())
    )
    
    # S√©lection du type d'√©chelle avec explication
    st.sidebar.markdown("""
    ### Type d'√©chelle
    - **0-1** : Les donn√©es doivent d√©j√† √™tre normalis√©es entre 0 et 1
    - **free** : Les donn√©es seront automatiquement normalis√©es
    """)
    
    scale_type = st.sidebar.selectbox(
        "Choisir le type d'√©chelle",
        options=['free', '0-1'],  # Mettre 'free' par d√©faut
        index=0  # S√©lectionner 'free' par d√©faut
    )
    
    if mca_file and mcp_file:
        try:
            # Lecture des fichiers avec plus de param√®tres
            mca_data = pd.read_csv(mca_file, 
                                 index_col=0,
                                 sep=None,
                                 engine='python',
                                 decimal=',',
                                 dtype=str)  # Lire toutes les colonnes comme texte d'abord
            mcp_data = pd.read_csv(mcp_file,
                                 index_col=0,
                                 sep=None,
                                 engine='python',
                                 decimal=',',
                                 dtype=str)  # Lire toutes les colonnes comme texte d'abord
            
            # Conversion propre en num√©rique
            for df in [mca_data, mcp_data]:
                for col in df.columns:
                    # Nettoyer les donn√©es avant conversion
                    df[col] = (df[col]
                             .str.strip()  # Enlever les espaces
                             .str.replace(',', '.')  # Remplacer les virgules par des points
                             .str.replace(' ', '')  # Enlever les espaces dans les nombres
                             )
                    # Convertir en num√©rique
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # V√©rifier si la conversion a r√©ussi
            if mca_data.isna().any().any():
                st.warning("Certaines valeurs dans MCA ont √©t√© converties en NaN. V√©rifiez vos donn√©es.")
                st.write("Colonnes avec des NaN dans MCA:", mca_data.columns[mca_data.isna().any()].tolist())
            
            if mcp_data.isna().any().any():
                st.warning("Certaines valeurs dans MCP ont √©t√© converties en NaN. V√©rifiez vos donn√©es.")
                st.write("Colonnes avec des NaN dans MCP:", mcp_data.columns[mcp_data.isna().any()].tolist())
                return
            
            # V√©rifier et normaliser les donn√©es selon le type d'√©chelle
            if scale_type == '0-1':
                # V√©rifier si les donn√©es sont d√©j√† entre 0 et 1
                if ((mca_data.values < 0).any() or (mca_data.values > 1).any() or 
                    (mcp_data.values < 0).any() or (mcp_data.values > 1).any()):
                    st.error("""
                    Les donn√©es ne sont pas dans l'intervalle [0,1].
                    Pour des donn√©es non normalis√©es, utilisez l'option 'free'.
                    """)
                    return
            else:  # scale_type == 'free'
                # Normaliser les donn√©es entre 0 et 1
                from sklearn.preprocessing import MinMaxScaler
                scaler = MinMaxScaler()
                
                # Normaliser MCA
                mca_values = scaler.fit_transform(mca_data)
                mca_data = pd.DataFrame(
                    mca_values,
                    index=mca_data.index,
                    columns=mca_data.columns
                )
                
                # Normaliser MCP
                mcp_values = scaler.fit_transform(mcp_data)
                mcp_data = pd.DataFrame(
                    mcp_values,
                    index=mcp_data.index,
                    columns=mcp_data.columns
                )
                
                st.info("Les donn√©es ont √©t√© automatiquement normalis√©es entre 0 et 1")
            
            # Afficher les plages de valeurs apr√®s normalisation
            st.write("Plage de valeurs apr√®s traitement :")
            st.write(f"MCA : [{mca_data.values.min():.2f}, {mca_data.values.max():.2f}]")
            st.write(f"MCP : [{mcp_data.values.min():.2f}, {mcp_data.values.max():.2f}]")
            
            # Afficher les informations sur les donn√©es charg√©es
            st.write("Aper√ßu des donn√©es MCA :")
            st.write(f"Dimensions MCA : {mca_data.shape}")
            st.write(mca_data.head())
            
            st.write("Aper√ßu des donn√©es MCP :")
            st.write(f"Dimensions MCP : {mcp_data.shape}")
            st.write(mcp_data.head())
            
            # Configuration du logger avec plus de d√©tails
            import logging
            logger = logging.getLogger('streamlit_logger')
            logger.setLevel(logging.INFO)
            
            # Cr√©er un conteneur pour les logs
            log_container = st.expander("Logs de traitement", expanded=False)
            log_text = []
            
            # Ajout d'un handler pour collecter les logs
            class StreamlitHandler(logging.Handler):
                def emit(self, record):
                    log_msg = record.getMessage()
                    log_text.append(log_msg)
                    # Mettre √† jour la zone de texte avec tous les logs
                    with log_container:
                        st.text_area(
                            "D√©tails du traitement",
                            value="\n".join(log_text),
                            height=200,
                            disabled=True
                        )
            
            logger.addHandler(StreamlitHandler())
            
            # Nettoyer le dossier des figures avant le traitement
            figures_dir = 'data/output/figures'
            os.makedirs(figures_dir, exist_ok=True)
            for f in os.listdir(figures_dir):
                if f.endswith('.png'):
                    os.remove(os.path.join(figures_dir, f))
            
            # Traitement MCAP
            model_function = getattr(ModelFunctions, f"model_function{selected_model[-1]}")
            processor = McapProcessor(
                logger=logger,
                mca_matrix=mca_data,
                mcp_matrix=mcp_data,
                model_function=model_function,
                scale_type=scale_type
            )
            
            # Ex√©cution du traitement
            if processor.process() == 0:
                st.success("Traitement termin√© avec succ√®s!")
                
                # Affichage des r√©sultats CSV
                if os.path.exists('data/output/ranking_matrix.csv'):
                    results = pd.read_csv('data/output/ranking_matrix.csv')
                    st.write("R√©sultats de l'affectation :")
                    st.dataframe(results)
                
                # Affichage des r√©sultats d√©taill√©s en format texte
                if os.path.exists('data/output/ranking_results.txt'):
                    with open('data/output/ranking_results.txt', 'r') as f:
                        results_text = f.read()
                    
                    # Cr√©er un expander avec un titre color√©
                    results_container = st.expander(
                        "üìä R√©sultats d√©taill√©s par activit√©",
                        expanded=False
                    )
                    with results_container:
                        st.markdown(
                            """
                            <div style='background-color: #0066cc; padding: 10px; border-radius: 5px;'>
                                <h3 style='color: white; margin: 0;'>Classement d√©taill√© des profils</h3>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                        st.text_area(
                            "",
                            value=results_text,
                            height=300,
                            disabled=True
                        )
                
                # Affichage des graphiques
                st.write("## Visualisations des r√©sultats")
                
                # R√©cup√©rer et trier les fichiers de graphiques par type
                graph_files = os.listdir('data/output/figures')
                radar_graphs = sorted([f for f in graph_files if f.startswith('radar_pentagon_')])
                bar_graphs = sorted([f for f in graph_files if f.startswith('affectation_bar_')])
                
                # Afficher les graphiques radar
                if radar_graphs:
                    st.markdown("""
                    ### üìä Graphiques Radar par Activit√©
                    Visualisation des scores pour chaque profil par activit√©
                    """)
                    
                    # Calculer le nombre de colonnes en fonction du nombre de graphiques
                    n_cols = min(2, len(radar_graphs))  # Maximum 2 colonnes
                    cols = st.columns(n_cols)
                    
                    for idx, fig_file in enumerate(radar_graphs):
                        with cols[idx % n_cols]:
                            st.image(
                                f'data/output/figures/{fig_file}',
                                use_column_width=True,
                                caption=f"Radar {idx+1}"
                            )
                
                # Afficher le graphique en barres
                if bar_graphs:
                    st.markdown("""
                    ### üìà Vue d'ensemble des affectations
                    Distribution globale des scores par profil et activit√©
                    """)
                    for fig_file in bar_graphs:
                        st.image(
                            f'data/output/figures/{fig_file}',
                            use_column_width=True
                        )
            else:
                st.error("Une erreur s'est produite pendant le traitement")
                
        except Exception as e:
            st.error(f"Erreur d√©taill√©e : {str(e)}")
            st.error(f"Type d'erreur : {type(e).__name__}")
            import traceback
            st.error(f"Traceback : {traceback.format_exc()}")

if __name__ == "__main__":
    run_streamlit_app()